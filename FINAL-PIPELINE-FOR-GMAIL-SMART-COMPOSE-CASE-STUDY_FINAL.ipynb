{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:06.752770Z",
     "iopub.status.busy": "2022-06-28T14:09:06.752268Z",
     "iopub.status.idle": "2022-06-28T14:09:18.433873Z",
     "shell.execute_reply": "2022-06-28T14:09:18.432286Z",
     "shell.execute_reply.started": "2022-06-28T14:09:06.752663Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import email\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import re\n",
    "import nltk\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import concatenate\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading all the pickled data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:18.439344Z",
     "iopub.status.busy": "2022-06-28T14:09:18.437709Z",
     "iopub.status.idle": "2022-06-28T14:09:18.639027Z",
     "shell.execute_reply": "2022-06-28T14:09:18.637758Z",
     "shell.execute_reply.started": "2022-06-28T14:09:18.439287Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_Encoder_input=pickle.load(open(\"../input/final-trained-encoder-decoder-models/X_train_Encoder_input.pkl\",\"rb\"))\n",
    "X_test_Encoder_input=pickle.load(open(\"../input/final-trained-encoder-decoder-models/X_test_Encoder_input.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:18.641170Z",
     "iopub.status.busy": "2022-06-28T14:09:18.640788Z",
     "iopub.status.idle": "2022-06-28T14:09:18.829645Z",
     "shell.execute_reply": "2022-06-28T14:09:18.828340Z",
     "shell.execute_reply.started": "2022-06-28T14:09:18.641137Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_Decoder_input=pickle.load(open(\"../input/final-trained-encoder-decoder-models/X_train_Decoder_input.pkl\",\"rb\"))\n",
    "X_test_Decoder_input=pickle.load(open(\"../input/final-trained-encoder-decoder-models/X_test_Decoder_input.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:18.835391Z",
     "iopub.status.busy": "2022-06-28T14:09:18.835002Z",
     "iopub.status.idle": "2022-06-28T14:09:19.007497Z",
     "shell.execute_reply": "2022-06-28T14:09:19.006107Z",
     "shell.execute_reply.started": "2022-06-28T14:09:18.835357Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train_Decoder_output=pickle.load(open(\"../input/final-trained-encoder-decoder-models/X_train_Decoder_output.pkl\",\"rb\"))\n",
    "X_test_Decoder_output=pickle.load(open(\"../input/final-trained-encoder-decoder-models/X_test_Decoder_output.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:19.009315Z",
     "iopub.status.busy": "2022-06-28T14:09:19.008992Z",
     "iopub.status.idle": "2022-06-28T14:09:19.017338Z",
     "shell.execute_reply": "2022-06-28T14:09:19.016000Z",
     "shell.execute_reply.started": "2022-06-28T14:09:19.009285Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data Encoder input length 21\n",
      "train data Deccoder input length 20\n",
      "train data Deccoder output length 20\n"
     ]
    }
   ],
   "source": [
    "print(\"train data Encoder input length {}\".format(X_train_Encoder_input.shape[1]))\n",
    "print(\"train data Deccoder input length {}\".format(X_train_Decoder_input.shape[1]))\n",
    "print(\"train data Deccoder output length {}\".format(X_train_Decoder_output.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:19.019977Z",
     "iopub.status.busy": "2022-06-28T14:09:19.018778Z",
     "iopub.status.idle": "2022-06-28T14:09:19.029753Z",
     "shell.execute_reply": "2022-06-28T14:09:19.028392Z",
     "shell.execute_reply.started": "2022-06-28T14:09:19.019940Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data Encoder input length 21\n",
      "test data Deccoder input length 20\n",
      "test data Deccoder output length 20\n"
     ]
    }
   ],
   "source": [
    "print(\"test data Encoder input length {}\".format(X_test_Encoder_input.shape[1]))\n",
    "print(\"test data Deccoder input length {}\".format(X_test_Decoder_input.shape[1]))\n",
    "print(\"test data Deccoder output length {}\".format(X_test_Decoder_output.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:19.034358Z",
     "iopub.status.busy": "2022-06-28T14:09:19.032575Z",
     "iopub.status.idle": "2022-06-28T14:09:19.154891Z",
     "shell.execute_reply": "2022-06-28T14:09:19.153931Z",
     "shell.execute_reply.started": "2022-06-28T14:09:19.034306Z"
    }
   },
   "outputs": [],
   "source": [
    "Enc_Tokenizer=pickle.load(open(\"../input/final-trained-encoder-decoder-models/Enc_Tokenizer.pkl\",\"rb\"))\n",
    "Dec_Tokenizer=pickle.load(open(\"../input/final-trained-encoder-decoder-models/Dec_Tokenizer.pkl\",\"rb\"))\n",
    "Dec_Tokenizer_target=pickle.load(open(\"../input/final-trained-encoder-decoder-models/Dec_Tokenizer_target.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:19.157512Z",
     "iopub.status.busy": "2022-06-28T14:09:19.156553Z",
     "iopub.status.idle": "2022-06-28T14:09:19.170076Z",
     "shell.execute_reply": "2022-06-28T14:09:19.168940Z",
     "shell.execute_reply.started": "2022-06-28T14:09:19.157469Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating the dictiionary with output vocab words\n",
    "target_token_index=Dec_Tokenizer_target.word_index\n",
    "reverse_target_char_index = dict((i, word) for word, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:19.172331Z",
     "iopub.status.busy": "2022-06-28T14:09:19.171869Z",
     "iopub.status.idle": "2022-06-28T14:09:19.181774Z",
     "shell.execute_reply": "2022-06-28T14:09:19.181044Z",
     "shell.execute_reply.started": "2022-06-28T14:09:19.172287Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input vocab length 19419\n",
      "output vocab length 20955\n"
     ]
    }
   ],
   "source": [
    "input_vocab=len(Enc_Tokenizer.word_index)+1\n",
    "output_vocab=len(Dec_Tokenizer_target.word_index)+1\n",
    "print(\"input vocab length {}\".format(input_vocab))\n",
    "print(\"output vocab length {}\".format(output_vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defined the function to calculate the perplexity the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:19.186432Z",
     "iopub.status.busy": "2022-06-28T14:09:19.185682Z",
     "iopub.status.idle": "2022-06-28T14:09:19.195546Z",
     "shell.execute_reply": "2022-06-28T14:09:19.194599Z",
     "shell.execute_reply.started": "2022-06-28T14:09:19.186401Z"
    }
   },
   "outputs": [],
   "source": [
    "def perplexity(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    this function will calculate perplexity metric by calculates the cross entropy loss and takes its exponent for train and test dataset\n",
    "    \"\"\"\n",
    "    return keras.backend.exp(keras.backend.mean(keras.backend.sparse_categorical_crossentropy(y_true, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:19.197329Z",
     "iopub.status.busy": "2022-06-28T14:09:19.196807Z",
     "iopub.status.idle": "2022-06-28T14:09:19.207275Z",
     "shell.execute_reply": "2022-06-28T14:09:19.206432Z",
     "shell.execute_reply.started": "2022-06-28T14:09:19.197290Z"
    }
   },
   "outputs": [],
   "source": [
    "## defining some vairable like embedding size , number of gru or lstm units batch size and epochs we are going to run to train the model\n",
    "embedding_dim=100    \n",
    "latent_dim= 100      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bidirectional GRU based Encoder Decoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:19.209104Z",
     "iopub.status.busy": "2022-06-28T14:09:19.208315Z",
     "iopub.status.idle": "2022-06-28T14:09:20.093153Z",
     "shell.execute_reply": "2022-06-28T14:09:20.091878Z",
     "shell.execute_reply.started": "2022-06-28T14:09:19.209066Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-28 14:09:19.269292: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 21)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 21, 100)      1941900     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   [(None, 21, 200), (N 121200      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 100)    2095500     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 200)          0           bidirectional[0][1]              \n",
      "                                                                 bidirectional[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "gru_1 (GRU)                     [(None, None, 200),  181200      embedding_1[0][0]                \n",
      "                                                                 concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 20955)  4211955     gru_1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 8,551,755\n",
      "Trainable params: 8,551,755\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Bidirectional GRU Encoder layer\n",
    "encoder_in_layer = tf.keras.layers.Input(shape=(X_train_Encoder_input.shape[1],))\n",
    "\n",
    "encoder_embedding = tf.keras.layers.Embedding(input_dim=input_vocab, output_dim=embedding_dim)\n",
    "\n",
    "encoder_bi_gru = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(units=latent_dim, return_sequences=True, return_state=True))\n",
    "\n",
    "# Discard the encoder output and use hidden states (h) of forward and backward layer\n",
    "encoder_out, fstate_h,bstate_h= encoder_bi_gru(encoder_embedding(encoder_in_layer))\n",
    "\n",
    "state_h = tf.keras.layers.Concatenate()([fstate_h, bstate_h])\n",
    "\n",
    "\n",
    "# forward only GRU Decoder layer\n",
    "decoder_in_layer = tf.keras.layers.Input(shape=(None,))\n",
    "\n",
    "decoder_embedding = tf.keras.layers.Embedding(input_dim=output_vocab, output_dim=embedding_dim)\n",
    "\n",
    "decoder_gru = tf.keras.layers.GRU(units=latent_dim*2, return_sequences=True, return_state=True)\n",
    "\n",
    "# Discard internal states in training, keep only the output sequence\n",
    "decoder_gru_out, _ = decoder_gru(decoder_embedding(decoder_in_layer), initial_state=state_h)\n",
    "\n",
    "decoder_dense = tf.keras.layers.Dense(output_vocab, activation=\"softmax\")\n",
    "\n",
    "decoder_out_layer = decoder_dense(decoder_gru_out)\n",
    "\n",
    "# Define the model that uses the Encoder and the Decoder\n",
    "model2 = tf.keras.models.Model([encoder_in_layer, decoder_in_layer], decoder_out_layer)\n",
    "\n",
    "model2.compile(optimizer='adam', loss=\"sparse_categorical_crossentropy\", metrics=[perplexity])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loading the pretained weighted which we have got during our training from best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:20.094737Z",
     "iopub.status.busy": "2022-06-28T14:09:20.094373Z",
     "iopub.status.idle": "2022-06-28T14:09:20.658476Z",
     "shell.execute_reply": "2022-06-28T14:09:20.657331Z",
     "shell.execute_reply.started": "2022-06-28T14:09:20.094701Z"
    }
   },
   "outputs": [],
   "source": [
    "model2.load_weights('../input/final-trained-encoder-decoder-models/Bi_gru_best_model_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loaded layer weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:20.660202Z",
     "iopub.status.busy": "2022-06-28T14:09:20.659895Z",
     "iopub.status.idle": "2022-06-28T14:09:20.700194Z",
     "shell.execute_reply": "2022-06-28T14:09:20.698909Z",
     "shell.execute_reply.started": "2022-06-28T14:09:20.660174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.34457716,  0.27720726, -0.13754787, ...,  0.24860892,\n",
       "        -0.10481738, -0.07865687],\n",
       "       [ 0.3367375 , -0.02528957,  0.06972946, ...,  0.5417424 ,\n",
       "        -0.00737609, -1.0066501 ],\n",
       "       [ 0.18133155,  0.18576327, -0.01458529, ..., -0.12290533,\n",
       "        -0.2844378 ,  0.12487155],\n",
       "       ...,\n",
       "       [-0.14527412, -0.08467149,  0.11735411, ..., -0.08907049,\n",
       "        -0.11917455,  0.04306293],\n",
       "       [-0.12630507, -0.00715517,  0.12349854, ...,  0.01107639,\n",
       "         0.04716697,  0.09069911],\n",
       "       [-0.12019105, -0.10082497,  0.17458011, ..., -0.073657  ,\n",
       "         0.14752027,  0.03755322]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the inference for final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:20.702298Z",
     "iopub.status.busy": "2022-06-28T14:09:20.701989Z",
     "iopub.status.idle": "2022-06-28T14:09:20.912477Z",
     "shell.execute_reply": "2022-06-28T14:09:20.911303Z",
     "shell.execute_reply.started": "2022-06-28T14:09:20.702270Z"
    }
   },
   "outputs": [],
   "source": [
    " # Inference Encoder\n",
    "encoder_model2 = tf.keras.models.Model(encoder_in_layer, state_h)\n",
    "\n",
    " # Inference Decoder\n",
    "state_input_h = tf.keras.layers.Input(shape=(latent_dim*2,))\n",
    "decoder_out, decoder_h = decoder_gru(decoder_embedding(decoder_in_layer), initial_state=state_input_h)\n",
    "decoder_out = decoder_dense(decoder_out)\n",
    "decoder_model2 = tf.keras.models.Model(inputs=[decoder_in_layer, state_input_h], \n",
    "                  outputs=[decoder_out, decoder_h])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining all the preprocessing function that i needed before final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:20.914533Z",
     "iopub.status.busy": "2022-06-28T14:09:20.914201Z",
     "iopub.status.idle": "2022-06-28T14:09:20.930031Z",
     "shell.execute_reply": "2022-06-28T14:09:20.928856Z",
     "shell.execute_reply.started": "2022-06-28T14:09:20.914503Z"
    }
   },
   "outputs": [],
   "source": [
    "def email_content(data):\n",
    "    '''this function will get the email body text messsages'''\n",
    "    mail_content = []\n",
    "    for i in tqdm(data):\n",
    "        message = email.message_from_string(i)\n",
    "        mail_content.append(message.get_payload())\n",
    "    return mail_content\n",
    "\n",
    "CONTRACTION_MAP=pickle.load(open('../input/final-trained-encoder-decoder-models/CONTRACTION_MAP.pkl','rb'))# loading the contraction map \n",
    "\n",
    "def decontracted(text):\n",
    "    '''this function will Replace all apostrophe/short words from text data'''\n",
    "    for word in text.split():\n",
    "        if word.lower() in CONTRACTION_MAP:\n",
    "            text = text.replace(word, CONTRACTION_MAP[word.lower()])\n",
    "    return text\n",
    "\n",
    "def data_preprocess(text):\n",
    "    '''This function will will preprocess the data by removing the puchuation digit email address and all non alphabet wrods from text.'''\n",
    "    \n",
    "    text=text.lower()\n",
    "    text = re.sub(r'\\.+', \".\", text) #Replace multiple fullstops with single fullstop\n",
    "\n",
    "    text = re.sub(r\"[^a-zA-Z?.!,']+\", \" \", text)# replacing everything with space except (a-z, \".\", \"?\", \"!\", \",\", \"'\")\n",
    "\n",
    "    # Compact spaces\n",
    "    text = re.sub(r'[\" \"]+', \" \", text)\n",
    "\n",
    "    # Remove forwarded messages\n",
    "    text = text.split('forwarded by')[0]\n",
    "\n",
    "    final_text = text.strip()\n",
    "\n",
    "\n",
    "    return final_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# defined the functon which give predicted sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:20.933333Z",
     "iopub.status.busy": "2022-06-28T14:09:20.932999Z",
     "iopub.status.idle": "2022-06-28T14:09:20.944501Z",
     "shell.execute_reply": "2022-06-28T14:09:20.943360Z",
     "shell.execute_reply.started": "2022-06-28T14:09:20.933291Z"
    }
   },
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    '''this function will predict the next words sequences given the input sequences'''\n",
    "    \n",
    "    if input_seq.split(' ')[0] != '<start>' and input_seq.split(' ')[-1] != '<end>':\n",
    "        input_seq = '<start>'+ ' ' + input_seq + ' ' + '<end>'\n",
    "    \n",
    "    #print(\"input seq\",input_seq)\n",
    "    input_seq = Enc_Tokenizer.texts_to_sequences([str(input_seq)])\n",
    "    input_seq = pad_sequences(input_seq, padding=\"post\",maxlen= 21)\n",
    "    \n",
    "     # Encode the input as state vectors.\n",
    "    state = encoder_model2.predict(input_seq)\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    target_seq[0, 0] = Dec_Tokenizer.word_index['<start>']\n",
    "    \n",
    "    # Encode the input as state vectors.\n",
    "    curr_word = \"<start>\"\n",
    "    decoded_sentence = ''\n",
    "\n",
    "    i = 0\n",
    "    while curr_word != \"<end>\" and i < (20 - 1):\n",
    "        output_tokens, h = decoder_model2.predict([target_seq, state])\n",
    "\n",
    "        curr_token = np.argmax(output_tokens[0, 0])\n",
    "\n",
    "        if (curr_token == 0):\n",
    "            break;\n",
    "\n",
    "        curr_word = reverse_target_char_index[curr_token]\n",
    "\n",
    "        decoded_sentence += ' ' + curr_word\n",
    "        target_seq[0, 0] = curr_token\n",
    "        state = h\n",
    "        i += 1\n",
    "    if curr_word != \"<end>\":\n",
    "        decoded_sentence += ' ' + '<end>'\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the function_1 which will take input here input can be single or set of datapoint and return the prediction of output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:20.946551Z",
     "iopub.status.busy": "2022-06-28T14:09:20.946235Z",
     "iopub.status.idle": "2022-06-28T14:09:20.974769Z",
     "shell.execute_reply": "2022-06-28T14:09:20.973468Z",
     "shell.execute_reply.started": "2022-06-28T14:09:20.946517Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_1(test):\n",
    "    \"\"\"this function will take dataset as input(single of set of datapoint) and perfrom data preprocessing and return the predictions as output\"\"\"\n",
    "    df_data=test.copy(deep=True) \n",
    "    \n",
    "    mail_content=email_content(df_data.message.values)\n",
    "    \n",
    "    df_data[\"mail_content\"]=mail_content\n",
    "    \n",
    "    df_data['mail_content_len'] = df_data['mail_content'].apply(len)\n",
    "    \n",
    "    \n",
    "    if len(test)>1:\n",
    "        emails_df_final = df_data[(df_data[\"mail_content_len\"] > 0) & (df_data[\"mail_content_len\"]< 5909)]\n",
    "        emails_df_final = df_data[(df_data[\"mail_content_len\"] > 0) & (df_data[\"mail_content_len\"]> 58)]\n",
    "    else:\n",
    "        emails_df_final=df_data\n",
    "    \n",
    "    emails_df_final['clean_mail_content'] = emails_df_final.apply(lambda x: data_preprocess(x[\"mail_content\"]),axis=1)\n",
    "    \n",
    "    \n",
    "    emails_df_final['clean_mail_content'] = emails_df_final.apply(lambda x: decontracted(x[\"clean_mail_content\"]),axis=1)\n",
    "    \n",
    "    #Droping the duplicates\n",
    "    emails_df_final.drop_duplicates(subset = \"clean_mail_content\",inplace=True)\n",
    "    \n",
    "    if len(test)>1:    \n",
    "        emails_df_final.drop([\"mail_content\",\"mail_content_len\"],axis=1,inplace=True)\n",
    "\n",
    "    \n",
    "    emails_df_final['clean_mail_content_len'] = emails_df_final['clean_mail_content'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
    "    \n",
    "    \n",
    "    if len(test)>1: \n",
    "        emails_df_final=emails_df_final[emails_df_final[\"clean_mail_content_len\"]<=20]\n",
    "    \n",
    "    output=[]\n",
    "    for i in tqdm(emails_df_final[\"clean_mail_content\"].values):\n",
    "        token_list=i.split()\n",
    "        for j in range(len(token_list)-1):\n",
    "            data = []\n",
    "            x_ngram =' '.join(token_list[:j+1]) \n",
    "            y_ngram =' '.join(token_list[j+1:])\n",
    "            data.append(x_ngram)\n",
    "            data.append(y_ngram)\n",
    "            output.append(data)\n",
    "    Final_df = pd.DataFrame(output, columns=['input','output'])\n",
    "    \n",
    "    \n",
    "    # Add start and end tokens to target sequences in oder to use teacher forcing traning method\n",
    "    Final_df[\"Encoder_input\"] = Final_df.input.apply(lambda x : '<start> '+ x + ' <end>')\n",
    "    \n",
    "    sample_data=Final_df\n",
    "    \n",
    "    if len(test)==1:\n",
    "        output=[]\n",
    "        for i in range(len(Final_df)):\n",
    "            data = []\n",
    "            data.append(sample_data[\"Encoder_input\"].iloc[i])\n",
    "            data.append(decode_sequence(sample_data[\"Encoder_input\"].iloc[i]))\n",
    "            output.append(data)\n",
    "        Predicted_df = pd.DataFrame(output, columns=['input','predicted'])\n",
    "    else:\n",
    "        output=[]\n",
    "        for i in range(2000):\n",
    "            data = []\n",
    "            data.append(sample_data[\"Encoder_input\"].iloc[i])\n",
    "            data.append(decode_sequence(sample_data[\"Encoder_input\"].iloc[i]))\n",
    "            output.append(data)\n",
    "        Predicted_df = pd.DataFrame(output, columns=['input','predicted'])\n",
    "    \n",
    "    return Predicted_df\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# laoding the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:20.976911Z",
     "iopub.status.busy": "2022-06-28T14:09:20.976480Z",
     "iopub.status.idle": "2022-06-28T14:09:46.910484Z",
     "shell.execute_reply": "2022-06-28T14:09:46.909185Z",
     "shell.execute_reply.started": "2022-06-28T14:09:20.976875Z"
    }
   },
   "outputs": [],
   "source": [
    "emails_df  = pd.read_csv('../input/enron-email-dataset/emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:46.912640Z",
     "iopub.status.busy": "2022-06-28T14:09:46.912298Z",
     "iopub.status.idle": "2022-06-28T14:09:46.985464Z",
     "shell.execute_reply": "2022-06-28T14:09:46.984546Z",
     "shell.execute_reply.started": "2022-06-28T14:09:46.912608Z"
    }
   },
   "outputs": [],
   "source": [
    "emails_df.drop(['file'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:46.987308Z",
     "iopub.status.busy": "2022-06-28T14:09:46.986960Z",
     "iopub.status.idle": "2022-06-28T14:09:47.001707Z",
     "shell.execute_reply": "2022-06-28T14:09:47.000824Z",
     "shell.execute_reply.started": "2022-06-28T14:09:46.987277Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Message-ID: &lt;18782981.1075855378110.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Message-ID: &lt;15464986.1075855378456.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Message-ID: &lt;24216240.1075855687451.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Message-ID: &lt;13505866.1075863688222.JavaMail.e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Message-ID: &lt;30922949.1075863688243.JavaMail.e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message\n",
       "0  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
       "1  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
       "2  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
       "3  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
       "4  Message-ID: <30922949.1075863688243.JavaMail.e..."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing the single data point to function_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:47.061044Z",
     "iopub.status.busy": "2022-06-28T14:09:47.059956Z",
     "iopub.status.idle": "2022-06-28T14:09:51.679745Z",
     "shell.execute_reply": "2022-06-28T14:09:51.678641Z",
     "shell.execute_reply.started": "2022-06-28T14:09:47.060914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 1127.80it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 3771.86it/s]\n",
      "2022-06-28 14:09:47.151975: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "Predicted_df_single_data_pts=function_1(emails_df.iloc[[0],:])#this will give single row from dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predicted output from our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:51.683156Z",
     "iopub.status.busy": "2022-06-28T14:09:51.681118Z",
     "iopub.status.idle": "2022-06-28T14:09:51.693764Z",
     "shell.execute_reply": "2022-06-28T14:09:51.693009Z",
     "shell.execute_reply.started": "2022-06-28T14:09:51.683120Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;start&gt; let &lt;end&gt;</td>\n",
       "      <td>me know if you are going to decide quickly. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;start&gt; let me &lt;end&gt;</td>\n",
       "      <td>know if you have any questions. also, very important that this goes out today. kay &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;start&gt; let me know &lt;end&gt;</td>\n",
       "      <td>if you have any questions. also, very important that this goes out today. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;start&gt; let me know if &lt;end&gt;</td>\n",
       "      <td>you are read on this. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          input  \\\n",
       "0  <start> let <end>              \n",
       "1  <start> let me <end>           \n",
       "2  <start> let me know <end>      \n",
       "3  <start> let me know if <end>   \n",
       "\n",
       "                                                                                   predicted  \n",
       "0   me know if you are going to decide quickly. <end>                                         \n",
       "1   know if you have any questions. also, very important that this goes out today. kay <end>  \n",
       "2   if you have any questions. also, very important that this goes out today. <end>           \n",
       "3   you are read on this. <end>                                                               "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', -1)\n",
    "Predicted_df_single_data_pts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# As in our orignal dataset we have almost 5 lakh row so here we are randomly sampling 2000 data points and pasing it functon_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:47.004687Z",
     "iopub.status.busy": "2022-06-28T14:09:47.004236Z",
     "iopub.status.idle": "2022-06-28T14:09:47.030591Z",
     "shell.execute_reply": "2022-06-28T14:09:47.029402Z",
     "shell.execute_reply.started": "2022-06-28T14:09:47.004644Z"
    }
   },
   "outputs": [],
   "source": [
    "emails_df=emails_df.sample(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:09:51.695935Z",
     "iopub.status.busy": "2022-06-28T14:09:51.695268Z",
     "iopub.status.idle": "2022-06-28T14:29:36.256639Z",
     "shell.execute_reply": "2022-06-28T14:29:36.255246Z",
     "shell.execute_reply.started": "2022-06-28T14:09:51.695902Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:00<00:00, 5439.32it/s]\n",
      "100%|██████████| 208/208 [00:00<00:00, 15427.60it/s]\n"
     ]
    }
   ],
   "source": [
    "Predicted_df=function_1(emails_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predction for 2000 datapoint from out model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:29:36.264225Z",
     "iopub.status.busy": "2022-06-28T14:29:36.263780Z",
     "iopub.status.idle": "2022-06-28T14:29:36.278865Z",
     "shell.execute_reply": "2022-06-28T14:29:36.277712Z",
     "shell.execute_reply.started": "2022-06-28T14:29:36.264189Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1887</th>\n",
       "      <td>&lt;start&gt; don i have offers for carrie and &lt;end&gt;</td>\n",
       "      <td>provide the interest for the new company? thanx, chris &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1032</th>\n",
       "      <td>&lt;start&gt; fyi also, mike and i are working with tim to &lt;end&gt;</td>\n",
       "      <td>take a look at this. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>&lt;start&gt; while i'm still making &lt;end&gt;</td>\n",
       "      <td>the letter of the month of recruiting for the gas trading agreement. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>&lt;start&gt; richard we actually need to duplicate his ena workstation as &lt;end&gt;</td>\n",
       "      <td>will not be able to read enron &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254</th>\n",
       "      <td>&lt;start&gt; ken &lt;end&gt;</td>\n",
       "      <td>lay's office n. sent from my blackberry wireless handheld www.blackberry.net &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>&lt;start&gt; did you have a chance to talk &lt;end&gt;</td>\n",
       "      <td>to lisa? &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>&lt;start&gt; update from cera on pricing and rest &lt;end&gt;</td>\n",
       "      <td>of the season. &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>&lt;start&gt; attached is the weekly report for &lt;end&gt;</td>\n",
       "      <td>the week ending . morgan gottsponer &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>&lt;start&gt; guys, please take a read of the draft &lt;end&gt;</td>\n",
       "      <td>amendment for the review. thanks. mike green leslie &lt;end&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1348</th>\n",
       "      <td>&lt;start&gt; louise, attached &lt;end&gt;</td>\n",
       "      <td>is the spreadsheet that you requested. thanks, chris &lt;end&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           input  \\\n",
       "1887  <start> don i have offers for carrie and <end>                               \n",
       "1032  <start> fyi also, mike and i are working with tim to <end>                   \n",
       "617   <start> while i'm still making <end>                                         \n",
       "859   <start> richard we actually need to duplicate his ena workstation as <end>   \n",
       "254   <start> ken <end>                                                            \n",
       "1547  <start> did you have a chance to talk <end>                                  \n",
       "1731  <start> update from cera on pricing and rest <end>                           \n",
       "314   <start> attached is the weekly report for <end>                              \n",
       "729   <start> guys, please take a read of the draft <end>                          \n",
       "1348  <start> louise, attached <end>                                               \n",
       "\n",
       "                                                                                predicted  \n",
       "1887   provide the interest for the new company? thanx, chris <end>                        \n",
       "1032   take a look at this. <end>                                                          \n",
       "617    the letter of the month of recruiting for the gas trading agreement. <end>          \n",
       "859    will not be able to read enron <end>                                                \n",
       "254    lay's office n. sent from my blackberry wireless handheld www.blackberry.net <end>  \n",
       "1547   to lisa? <end>                                                                      \n",
       "1731   of the season. <end>                                                                \n",
       "314    the week ending . morgan gottsponer <end>                                           \n",
       "729    amendment for the review. thanks. mike green leslie <end>                           \n",
       "1348   is the spreadsheet that you requested. thanks, chris <end>                          "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('max_colwidth', -1)\n",
    "Predicted_df.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the function which will take dataset with X and Y values and return the perplexity on same dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:29:36.281133Z",
     "iopub.status.busy": "2022-06-28T14:29:36.280739Z",
     "iopub.status.idle": "2022-06-28T14:29:36.314950Z",
     "shell.execute_reply": "2022-06-28T14:29:36.313713Z",
     "shell.execute_reply.started": "2022-06-28T14:29:36.281099Z"
    }
   },
   "outputs": [],
   "source": [
    "def function_2(test):\n",
    "    \"\"\"this function will take dataset (with x and y) as input and perfrom data preprocessing and return the perplexity of model\"\"\"\n",
    "    df_data=test.copy(deep=True) \n",
    "    \n",
    "    mail_content=email_content(df_data.message.values)\n",
    "    \n",
    "    df_data[\"mail_content\"]=mail_content\n",
    "    \n",
    "    df_data['mail_content_len'] = df_data['mail_content'].apply(len)\n",
    "    \n",
    "    emails_df_final = df_data[(df_data[\"mail_content_len\"] > 0) & (df_data[\"mail_content_len\"]< 5909)]\n",
    "    emails_df_final = df_data[(df_data[\"mail_content_len\"] > 0) & (df_data[\"mail_content_len\"]> 58)]\n",
    "    \n",
    "    emails_df_final['clean_mail_content'] = emails_df_final.apply(lambda x: data_preprocess(x[\"mail_content\"]),axis=1)\n",
    "    \n",
    "    emails_df_final['clean_mail_content'] = emails_df_final.apply(lambda x: decontracted(x[\"clean_mail_content\"]),axis=1)\n",
    "    \n",
    "    #Droping the duplicates\n",
    "    emails_df_final.drop_duplicates(subset = \"clean_mail_content\",inplace=True)\n",
    "    \n",
    "        \n",
    "    emails_df_final.drop([\"mail_content\",\"mail_content_len\"],axis=1,inplace=True)\n",
    "    \n",
    "    emails_df_final['clean_mail_content_len'] = emails_df_final['clean_mail_content'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
    "    \n",
    "    emails_df_final=emails_df_final[emails_df_final[\"clean_mail_content_len\"]<=20]\n",
    "    \n",
    "    output=[]\n",
    "    for i in tqdm(emails_df_final[\"clean_mail_content\"].values):\n",
    "        token_list=i.split()\n",
    "        for j in range(len(token_list)-1):\n",
    "            data = []\n",
    "            x_ngram =' '.join(token_list[:j+1]) \n",
    "            y_ngram =' '.join(token_list[j+1:])\n",
    "            data.append(x_ngram)\n",
    "            data.append(y_ngram)\n",
    "            output.append(data)\n",
    "    Final_df = pd.DataFrame(output, columns=['input','output'])\n",
    "    \n",
    "    # Add start and end tokens to target sequences in oder to use teacher forcing traning method\n",
    "    Final_df[\"Encoder_input\"] = Final_df.input.apply(lambda x : '<start> '+ x + ' <end>')\n",
    "    Final_df[\"Decoder_input\"] = Final_df.output.apply(lambda x : '<start> '+ x)\n",
    "    Final_df[\"Decoder_output\"] = Final_df.output.apply(lambda x : x + ' <end>')\n",
    "    \n",
    "    Enc_Tokenizer=pickle.load(open(\"../input/final-trained-encoder-decoder-models/Enc_Tokenizer.pkl\",\"rb\"))\n",
    "    Dec_Tokenizer=pickle.load(open(\"../input/final-trained-encoder-decoder-models/Dec_Tokenizer.pkl\",\"rb\"))\n",
    "    Dec_Tokenizer_target=pickle.load(open(\"../input/final-trained-encoder-decoder-models/Dec_Tokenizer_target.pkl\",\"rb\"))\n",
    "    \n",
    "    X_test_Encoder_input = Enc_Tokenizer.texts_to_sequences( Final_df[\"Encoder_input\"])\n",
    "    X_test_Encoder_input = pad_sequences(X_test_Encoder_input, padding='post',maxlen= 21)\n",
    "    \n",
    "    X_test_Decoder_input = Dec_Tokenizer.texts_to_sequences( Final_df[\"Decoder_input\"])\n",
    "    X_test_Decoder_input = pad_sequences(X_test_Decoder_input, padding='post',maxlen= 20)\n",
    "    \n",
    "    X_test_Decoder_output = Dec_Tokenizer_target.texts_to_sequences( Final_df[\"Decoder_output\"])\n",
    "    X_test_Decoder_output = pad_sequences(X_test_Decoder_output, padding='post',maxlen= 20)\n",
    "    \n",
    "    perplexity_scores = model2.evaluate([X_test_Encoder_input, X_test_Decoder_input], X_test_Decoder_output)\n",
    "    \n",
    "    return perplexity_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Again loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:29:36.316958Z",
     "iopub.status.busy": "2022-06-28T14:29:36.316400Z",
     "iopub.status.idle": "2022-06-28T14:29:54.689523Z",
     "shell.execute_reply": "2022-06-28T14:29:54.688178Z",
     "shell.execute_reply.started": "2022-06-28T14:29:36.316925Z"
    }
   },
   "outputs": [],
   "source": [
    "emails_df  = pd.read_csv('../input/enron-email-dataset/emails.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:29:54.691799Z",
     "iopub.status.busy": "2022-06-28T14:29:54.691336Z",
     "iopub.status.idle": "2022-06-28T14:29:54.759172Z",
     "shell.execute_reply": "2022-06-28T14:29:54.758073Z",
     "shell.execute_reply.started": "2022-06-28T14:29:54.691757Z"
    }
   },
   "outputs": [],
   "source": [
    "emails_df.drop(['file'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# passing the whole dataset to function_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-28T14:29:54.761247Z",
     "iopub.status.busy": "2022-06-28T14:29:54.760866Z",
     "iopub.status.idle": "2022-06-28T15:10:23.027047Z",
     "shell.execute_reply": "2022-06-28T15:10:23.025898Z",
     "shell.execute_reply.started": "2022-06-28T14:29:54.761213Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 517401/517401 [01:38<00:00, 5241.63it/s]\n",
      "100%|██████████| 19069/19069 [00:01<00:00, 14418.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6588/6588 [==============================] - 1279s 194ms/step - loss: 0.3389 - perplexity: 1.4156\n"
     ]
    }
   ],
   "source": [
    "perplexity_scores=function_2(emails_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we have got the perplexity score on whole dataset as 1.4156 and loss as 0.3389 which is very good"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
